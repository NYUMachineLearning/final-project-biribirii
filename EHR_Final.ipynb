{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import merged df\n",
    "df = pd.read_csv('merged_df.csv',\n",
    "    index_col=False,\n",
    "    low_memory=False\n",
    ")\n",
    "# drop unncessary columns\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NA sum for each column\n",
    "for col in df.columns:\n",
    "    print(col, df[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values with 0 (alive) for 'deceased' column\n",
    "df['deceased'] = df['deceased'].fillna(value=0)\n",
    "\n",
    "# drop unwanted columns\n",
    "df = df.drop(['death_date_x', \n",
    "              'death_date_y', \n",
    "              'American Indian or Alaska Native_y',\n",
    "              'Asian_y', \n",
    "              'Unknown_y'], \n",
    "             axis=1)\n",
    "\n",
    "df.rename(columns={'Values_Average':'0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns with >= 55% NA\n",
    "df2 = df.loc[:, df.isnull().mean() < 0.55]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with median values\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='median')\n",
    "\n",
    "df_imp = df2.values\n",
    "df_imp = imp.fit_transform(df_imp)\n",
    "# rebuild df using index and column of original df\n",
    "df_imp = pd.DataFrame(data=df_imp, index=df2.index, columns=df2.columns)\n",
    "df_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NA sum for each column\n",
    "for col in df_imp.columns:\n",
    "    print(col, df_imp[col].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up features and labels for train/test\n",
    "features = df_new_imp.drop(['deceased', 'person_id'], axis=1) # drop only 'new bone formation' col\n",
    "labels = df_new_imp['deceased'] # single column with outcome of interest\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# barplot of outcome of interest\n",
    "# in our sample, deceased and alive are roughly equal\n",
    "sns.countplot(x=labels, data=df2, palette='Purples')\n",
    "plt.show()\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/Distribution.png', bbox_inches='tight')\n",
    "\n",
    "# train and test split 80:20\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(labels_train.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression modeling\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(features_train, labels_train)\n",
    "lr_pred = lr.predict(features_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.3f}'.format(lr.score(features_test, labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(labels_test, lr_pred)\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.heatmap(cm, cmap='Purples', annot=True, fmt='d', cbar=False, annot_kws = {\"size\": 15})\n",
    "plt.title('Logistic Regression \\nAccuracy:{0:.3f}'.format(accuracy_score(labels_test, lr_pred)), fontsize=15)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/LR_CM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "logit_roc_auc = roc_auc_score(labels_test, lr.predict(features_test))\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, lr.predict_proba(features_test)[:,1])\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.3f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/LR_ROC.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=10000, \n",
    "                            bootstrap = True,\n",
    "                            max_features = 'sqrt', \n",
    "                            oob_score=True)\n",
    "\n",
    "rf.fit(features_train, labels_train)\n",
    "rf_pred = rf.predict(features_test)\n",
    "rf_probs = rf.predict_proba(features_test)[:, 1]\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(labels_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "cm = confusion_matrix(labels_test, rf_pred)\n",
    "\n",
    "sns.heatmap(cm, cmap='Purples', annot=True, fmt='d', cbar=False, annot_kws = {\"size\": 15})\n",
    "plt.title('Random Forest \\nAccuracy:{0:.3f}'.format(accuracy_score(labels_test, rf_pred)), fontsize=15)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/RF_CM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "rf_roc = roc_auc_score(labels_test, rf_probs)\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, rf.predict_proba(features_test)[:,1])\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.plot(fpr, tpr, label='Random Forest (area = %0.3f)' % rf_roc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/RF_ROC.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance from random forest\n",
    "feature_imp = pd.Series(rf.feature_importances_, index=features_train.columns).sort_values(ascending=False)\n",
    "feature_imp\n",
    "\n",
    "features = feature_imp.iloc[0:5,]\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.barplot(x=features, y=features.index, palette='Purples_r')\n",
    "plt.xlabel('Feature Importance Score', fontsize=15)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title(\"Feature Importance\", fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/RF_Features.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top 20 features and re-test random forest\n",
    "top_20 = feature_imp.iloc[0:20,]\n",
    "death = df_imp['deceased']\n",
    "df_topfeatures = df_imp.loc[:,top_20.index]\n",
    "\n",
    "X = df_topfeatures # drop only 'new bone formation' col\n",
    "y = df_imp['deceased'] # single column with outcome of interest\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest on top 25 features\n",
    "rf = RandomForestClassifier(n_estimators=10000, \n",
    "                            bootstrap = True,\n",
    "                            max_features = 'sqrt', \n",
    "                            oob_score=True)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, rf_pred)\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.heatmap(cm, cmap='Purples', annot=True, fmt='d', cbar=False, annot_kws = {\"size\": 15})\n",
    "plt.title('Random Forest \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, rf_pred)), fontsize=15)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/RF_Features_CM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_roc = roc_auc_score(y_test, rf_probs)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, rf.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.plot(fpr, tpr, label='Random Forest (area = %0.3f)' % rf_roc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/RF_Features_ROC.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with Linear Kernel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "svm = LinearSVC(random_state=0, tol=1e-5, max_iter=2000)\n",
    "svm.fit(features_train, labels_train)\n",
    "clf = CalibratedClassifierCV(svm)\n",
    "clf.fit(features_train, labels_train)\n",
    "svm_pred = clf.predict(features_test)\n",
    "svm_probs = clf.predict_proba(features_test)[:, 1]\n",
    "print(\"SVM Linear Accuracy:\",metrics.accuracy_score(labels_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_roc = roc_auc_score(labels_test, svm_probs)\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, clf.predict_proba(features_test)[:,1])\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.plot(fpr, tpr, label='SVM Linear Kernel (AUC = %0.3f)' % svm_roc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_Linear_ROC.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels_test, svm_pred)\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "sns.heatmap(cm, cmap='Purples', annot=True, fmt='d', cbar=False, annot_kws = {\"size\": 15})\n",
    "plt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(labels_test, svm_pred)), fontsize=15)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_Linear_CM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract coefficients from SVM to list\n",
    "coef = svm.coef_\n",
    "\n",
    "coef = [y for x in coef for y in x]\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match features to coefficients\n",
    "features_svm = features.columns.to_series(index=range(len(features.columns)))\n",
    "coef = pd.Series(coef, index=range(len(features.columns)))\n",
    "features_svm.name = 'Features'\n",
    "coef.name = 'Coefficient'\n",
    "\n",
    "# concatenate features and coefficients to df\n",
    "feature_coef = pd.concat([features_svm, coef], axis=1)\n",
    "feature_coef.head()\n",
    "\n",
    "# sort by coefficients\n",
    "sort_coef = feature_coef.sort_values(by='Coefficient').reset_index(drop=True)\n",
    "sort_coef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save top 10 and bottom 10 features\n",
    "top_features = sort_coef.head(10).append(sort_coef.tail(10))\n",
    "\n",
    "# barplot of features\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.barplot(x='Coefficient', y='Features', data=top_features, palette='RdBu', order=top_features['Features'], orient='h')\n",
    "plt.xlabel('Coefficient', fontsize=15)\n",
    "plt.ylabel('')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.title('SVM Features', fontsize=20)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_Features.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with Linear Kernel Using Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_features = top_features['Features']\n",
    "\n",
    "X = features.loc[:,svm_features]\n",
    "y = df_new_imp['deceased'] # single column with outcome of interest\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "svm = LinearSVC(random_state=0, tol=1e-5)\n",
    "svm.fit(X_train, y_train)\n",
    "clf = CalibratedClassifierCV(svm)\n",
    "clf.fit(X_train, y_train)\n",
    "svm_pred = clf.predict(X_test)\n",
    "svm_probs = clf.predict_proba(X_test)[:, 1]\n",
    "print(\"SVM Linear Accuracy:\",metrics.accuracy_score(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_roc = roc_auc_score(y_test, svm_probs)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.plot(fpr, tpr, label='SVM Linear Kernel (AUC = %0.3f)' % svm_roc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.show()\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_Linear_ROC.png', bbox_inches='tight')\n",
    "\n",
    "cm = confusion_matrix(labels_test, svm_pred)\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.heatmap(cm, cmap='Purples', annot=True, fmt='d', cbar=False, annot_kws = {\"size\": 15})\n",
    "plt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, svm_pred)), fontsize=15)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_Linear_CM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = OneVsRestClassifier(SVC(kernel='rbf', probability=True, class_weight=None), n_jobs=-1)\n",
    "clf.fit(features_train, labels_train)\n",
    "svm_pred = clf.predict(features_test)\n",
    "svm_probs = clf.predict_proba(features_test)[:, 1]\n",
    "print(\"SVM RBF Accuracy:\",metrics.accuracy_score(labels_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_roc = roc_auc_score(labels_test, svm_probs)\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, clf.predict_proba(features_test)[:,1])\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.plot(fpr, tpr, label='SVM RBF Kernel (AUC = %0.3f)' % svm_roc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.show()\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_RBF_ROC.png', bbox_inches='tight')\n",
    "\n",
    "cm = confusion_matrix(labels_test, svm_pred)\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.heatmap(cm, cmap='Purples', annot=True, fmt='d', cbar=False, annot_kws = {\"size\": 15})\n",
    "plt.title('SVM RBF Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(labels_test, svm_pred)), fontsize=15)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_RBF_CM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(SVC(kernel='poly', degree=3, probability=True), n_jobs=-1)                                                                                    \n",
    "clf.fit(features_train, labels_train)\n",
    "svm_pred = clf.predict(features_test)\n",
    "svm_probs = clf.predict_proba(features_test)[:, 1]\n",
    "print(\"SVM Polynomial Accuracy:\",metrics.accuracy_score(labels_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_roc = roc_auc_score(labels_test, svm_probs)\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, clf.predict_proba(features_test)[:,1])\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.plot(fpr, tpr, label='SVM Polynomial Kernel (AUC = %0.3f)' % svm_roc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_POLY_ROC.png', bbox_inches='tight')\n",
    "\n",
    "cm = confusion_matrix(labels_test, svm_pred)\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.heatmap(cm, cmap='Purples', annot=True, fmt='d', cbar=False, annot_kws = {\"size\": 15})\n",
    "plt.title('SVM Sigmoid Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(labels_test, svm_pred)), fontsize=15)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_POLY_CM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(SVC(kernel='sigmoid', probability=True, class_weight=None), n_jobs=-1)\n",
    "clf.fit(features_train, labels_train)\n",
    "svm_pred = clf.predict(features_test)\n",
    "svm_probs = clf.predict_proba(features_test)[:, 1]\n",
    "print(\"SVM RBF Accuracy:\",metrics.accuracy_score(labels_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_roc = roc_auc_score(labels_test, svm_probs)\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, clf.predict_proba(features_test)[:,1])\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.plot(fpr, tpr, label='SVM Polynomial Kernel (AUC = %0.3f)' % svm_roc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_SIGMOID_ROC.png', bbox_inches='tight')\n",
    "\n",
    "cm = confusion_matrix(labels_test, svm_pred)\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.heatmap(cm, cmap='Purples', annot=True, fmt='d', cbar=False, annot_kws = {\"size\": 15})\n",
    "plt.title('SVM Sigmoid Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(labels_test, svm_pred)), fontsize=15)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/SVM_SIGMOID_CM.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "eval_set=[(features_test, labels_test)]\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(features_train, labels_train, eval_metric='error', eval_set=eval_set, verbose=True, early_stopping_rounds=25)\n",
    "xgb_probs = xgb.predict_proba(features_test)[:, 1]\n",
    "xgb_pred = xgb.predict(features_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(labels_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_roc = roc_auc_score(labels_test, xgb_probs)\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, xgb_probs)\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.plot(fpr, tpr, label='XGBoost (area = %0.3f)' % xgb_roc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.show()\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/XGB_ROC.png', bbox_inches='tight')\n",
    "\n",
    "cm = confusion_matrix(labels_test, xgb_pred)\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.heatmap(cm, cmap='Purples', annot=True, fmt='d', cbar=False, annot_kws = {\"size\": 15})\n",
    "plt.title('XGBoost \\nAccuracy:{0:.3f}'.format(accuracy_score(labels_test, xgb_pred)), fontsize=15)\n",
    "plt.ylabel('True label', fontsize=15)\n",
    "plt.xlabel('Predicted label', fontsize=15)\n",
    "plt.savefig('/gpfs/scratch/bcc276/EHR_Dream/Figures/XGB_CM.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
